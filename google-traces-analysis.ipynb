{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Análise de traços de execução</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Installs de bibliotecas necessárias</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in c:\\users\\322010\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: pyspark_dist_explore in c:\\users\\322010\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.1.8)\n",
      "Requirement already satisfied: pyspark in c:\\users\\322010\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement matplotlib.pyplot (from versions: none)\n",
      "ERROR: No matching distribution found for matplotlib.pyplot\n",
      "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\322010\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install findspark pyspark_dist_explore pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Primeiro utilizamos o findspark para que o ambiente saiba onde o spark está localizado.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Imports(têm de ser feitos após o init do findspark)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pyspark\n",
    "from pyspark_dist_explore import hist\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType,FloatType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Inicializamos uma seção Spark, ou pegamos a que está atualmente em execução</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName(\"Sessao\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Definimos um schema para o RDD</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_events_schema = StructType([ \\\n",
    "    StructField(\"time\",IntegerType(),True), \\\n",
    "    StructField(\"type\",IntegerType(),True), \\\n",
    "    StructField(\"collection_id\",IntegerType(),False), \\\n",
    "    StructField(\"priority\", IntegerType(), True), \\\n",
    "    StructField(\"instance_index\", IntegerType(), False), \\\n",
    "    StructField(\"cpu_resource_request\", FloatType(), True), \\\n",
    "    StructField(\"memory_resource_request\", FloatType(), True) \\\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Carregamos um arquivo CSV em um RDD(sem cabeçalho e com o schema definido)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddCE = spark.read.option(\"header\",\"true\").schema(instance_events_schema).csv(\"instance_events/instance_events-000000000000.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Média dos requerimentos de utilização de memória(por tipo de \"coisa\")</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Ao persistir o RDD, operações subsequentes reutilizarão os dados relativos ao RDD em operações que o envolvam, diminuindo drasticamente o tempo de execução das mesmas</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[time: int, type: int, collection_id: int, priority: int, instance_index: int, cpu_resource_request: float, memory_resource_request: float]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddCE.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Essa é executada sem cache</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------------------+\n",
      "|type|avg(memory_resource_request)|\n",
      "+----+----------------------------+\n",
      "|   0|        0.003215060709829252|\n",
      "|   1|         0.01933770519928046|\n",
      "|   2|        0.003345685608592...|\n",
      "|   3|        0.003335462585395...|\n",
      "|   4|        0.003473938670384...|\n",
      "|   5|        0.020445465992991966|\n",
      "|   6|        0.004764337917852076|\n",
      "|   7|        0.002935408097730315|\n",
      "|   8|        0.005776905272776365|\n",
      "|   9|        0.003988534368734...|\n",
      "|  10|        0.008756889907134162|\n",
      "+----+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rddCE.orderBy('type').groupBy('type').agg({\"`memory_resource_request`\":'avg'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Essa é executada COM cache</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------------+\n",
      "|type|avg(cpu_resource_request)|\n",
      "+----+-------------------------+\n",
      "|   0|     0.009525861089444346|\n",
      "|   1|     0.009540171341634771|\n",
      "|   2|     0.009649705901209166|\n",
      "|   3|     0.009805624388920475|\n",
      "|   4|     0.009645259130290452|\n",
      "|   5|     0.008741734786721873|\n",
      "|   6|     0.014509926217036775|\n",
      "|   7|     0.009677616500338168|\n",
      "|   8|     0.018229468438387228|\n",
      "|   9|     0.013241837398293013|\n",
      "|  10|     0.011053578572176771|\n",
      "+----+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rddCE.orderBy('type').groupBy('type').agg({\"`cpu_resource_request`\":'avg'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------------------+\n",
      "|type|avg(memory_resource_request)|\n",
      "+----+----------------------------+\n",
      "|   0|        0.003215060709829252|\n",
      "|   1|         0.01933770519928046|\n",
      "|   2|        0.003345685608592...|\n",
      "|   3|        0.003335462585395...|\n",
      "|   4|        0.003473938670384...|\n",
      "|   5|        0.020445465992991966|\n",
      "|   6|        0.004764337917852076|\n",
      "|   7|        0.002935408097730315|\n",
      "|   8|        0.005776905272776365|\n",
      "|   9|        0.003988534368734...|\n",
      "|  10|        0.008756889907134162|\n",
      "+----+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "aa8ee55327338118c9b4517d613770d195c366ac837f284f64f7c768461f394a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
